import streamlit as st
import torch
import torch.nn.functional as F
import cv2
import numpy as np
from PIL import Image
import tempfile
import time
import os
import logging
import onnxruntime as ort

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ç‰ç±³åç²’è¯†åˆ«å¹³å°",
    page_icon="ğŸŒ½",
    layout="wide"
)

# æ ‡é¢˜å’Œä»‹ç»
st.title("ğŸŒ½ ç‰ç±³åç²’è¯†åˆ«å¹³å°")
st.markdown("æœ¬å¹³å°åŸºäºæ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«ç‰ç±³ä¸­çš„åç²’ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿè¯„ä¼°ç‰ç±³è´¨é‡ã€‚")

# ä¾§è¾¹æ  - æ¨¡å‹è®¾ç½®
with st.sidebar:
    st.header("æ¨¡å‹è®¾ç½®")

    # æ·»åŠ è‡ªå®šä¹‰å’Œé»˜è®¤æŒ‰é’®
    custom_mode = st.button("è‡ªå®šä¹‰")
    default_mode = st.button("é»˜è®¤")

    if custom_mode:
        # ä¸Šä¼ æ¨¡å‹æƒé‡æ–‡ä»¶
        model_file = st.file_uploader("ä¸Šä¼ æ¨¡å‹æ–‡ä»¶", type=["pt", "pth", "onnx"])

        # é€‰æ‹©æ¨¡å‹ç±»å‹
        if model_file:
            file_ext = os.path.splitext(model_file.name)[1].lower()
            if file_ext == '.onnx':
                default_model_type = "ONNX"
            else:
                default_model_type = "PyTorch"

            model_type = st.selectbox(
                "æ¨¡å‹ç±»å‹",
                ["PyTorch", "TorchScript", "ONNX"],
                index=["PyTorch", "TorchScript", "ONNX"].index(default_model_type)
            )
        else:
            model_type = st.selectbox(
                "æ¨¡å‹ç±»å‹",
                ["PyTorch", "TorchScript", "ONNX"],
                index=0
            )
    elif default_mode:
        # é»˜è®¤ä½¿ç”¨modelæ–‡ä»¶å¤¹ä¸­çš„ptæ–‡ä»¶
        default_model_path = os.path.join("model", [f for f in os.listdir("model") if f.endswith('.pt')][0])
        class DummyFile:
            def __init__(self, path):
                self.name = path
                with open(path, 'rb') as f:
                    self.value = f.read()

            def getvalue(self):
                return self.value

        model_file = DummyFile(default_model_path)
        model_type = "PyTorch"
    else:
        model_file = None
        model_type = st.selectbox(
            "æ¨¡å‹ç±»å‹",
            ["PyTorch", "TorchScript", "ONNX"],
            index=0
        )

    confidence_threshold = st.slider(
        "ç½®ä¿¡åº¦é˜ˆå€¼",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.05
    )

    # é«˜çº§è®¾ç½®
    with st.expander("é«˜çº§è®¾ç½®"):
        draw_bbox = st.checkbox("æ˜¾ç¤ºè¾¹ç•Œæ¡†", value=True)
        draw_label = st.checkbox("æ˜¾ç¤ºæ ‡ç­¾", value=True)
        draw_confidence = st.checkbox("æ˜¾ç¤ºç½®ä¿¡åº¦", value=True)
        line_thickness = st.slider("è¾¹ç•Œæ¡†çº¿æ¡ç²—ç»†", min_value=1, max_value=10, value=2)
        detection_color = st.color_picker("åç²’æ ‡è®°é¢œè‰²", "#FF0000")

    st.header("å…³äº")
    st.info("""
    æœ¬å¹³å°ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹è¯†åˆ«ç‰ç±³åç²’ï¼Œæ”¯æŒå¤šç§æ ¼å¼çš„å›¾åƒè¾“å…¥ã€‚
    ä¸Šä¼ å›¾åƒåï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æ£€æµ‹å¹¶æ ‡è®°å‡ºåç²’åŒºåŸŸã€‚
    """)

try:
    from ultralytics import YOLO

    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False
    st.warning("æœªå®‰è£…ultralyticsåº“ï¼Œå¯èƒ½æ— æ³•åŠ è½½æŸäº›ç±»å‹çš„æ¨¡å‹ã€‚")


# åŠ è½½æ¨¡å‹
@st.cache_resource
def load_model(model_path, model_type):
    if not model_path:
        st.warning("æœªä¸Šä¼ æ¨¡å‹ï¼Œä½¿ç”¨ç¤ºä¾‹å‚æ•°ã€‚è¯·ä¸Šä¼ æ‚¨çš„æ¨¡å‹æ–‡ä»¶ä»¥è·å¾—å‡†ç¡®ç»“æœã€‚")
        return None

    try:
        st.info(f"æ­£åœ¨åŠ è½½{model_type}æ¨¡å‹: {model_path.name}")

        # ä¸´æ—¶ä¿å­˜ä¸Šä¼ çš„æ¨¡å‹æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(model_path.name)[1]) as tmp:
            tmp.write(model_path.getvalue())
            tmp_path = tmp.name

        if model_type == "ONNX":
            # åŠ è½½ONNXæ¨¡å‹
            model = ort.InferenceSession(
                tmp_path,
                providers=['CPUExecutionProvider']
            )
            st.success("ONNXæ¨¡å‹åŠ è½½æˆåŠŸï¼")
        else:
            # å°è¯•åŠ è½½ä¸ºUltralytics YOLOæ¨¡å‹
            if ULTRALYTICS_AVAILABLE:
                try:
                    model = YOLO(tmp_path)
                    st.success("Ultralytics YOLOæ¨¡å‹åŠ è½½æˆåŠŸï¼")
                    # ç‰¹æ®Šå¤„ç†ï¼šè°ƒæ•´ä¸ºè¯„ä¼°æ¨¡å¼
                    if hasattr(model, 'model') and hasattr(model.model, 'eval'):
                        model.model.eval()
                except Exception as e:
                    st.info(f"å°è¯•åŠ è½½ä¸ºUltralyticsæ¨¡å‹å¤±è´¥ï¼Œé”™è¯¯: {e}ã€‚å°è¯•å¸¸è§„åŠ è½½...")

                    # å°è¯•å¸¸è§„PyTorchåŠ è½½
                    if "DetectionModel" in str(e):
                        # å¤„ç†Ultralytics DetectionModelç±»æœªæ³¨å†Œçš„é—®é¢˜
                        try:
                            from ultralytics.nn.tasks import DetectionModel
                            # å…è®¸åŠ è½½DetectionModelç±»
                            torch.serialization.add_safe_globals([DetectionModel])

                            # ä½¿ç”¨weights_only=FalseåŠ è½½å®Œæ•´æ¨¡å‹
                            model = torch.load(tmp_path, map_location=torch.device('cpu'), weights_only=False)
                            st.success("PyTorchæ¨¡å‹åŠ è½½æˆåŠŸï¼ˆä½¿ç”¨weights_only=Falseï¼‰ï¼")

                            # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢ä¸ºevalæ¨¡å¼
                            if hasattr(model, 'eval'):
                                model = model.eval()
                        except Exception as e2:
                            st.error(f"åŠ è½½å¤±è´¥: {e2}")
                            raise e2
                    else:
                        # å°è¯•å¸¸è§„PyTorchåŠ è½½
                        try:
                            # å°è¯•å¸¸è§„åŠ è½½
                            model = torch.load(tmp_path, map_location=torch.device('cpu'))
                            st.success("PyTorchæ¨¡å‹åŠ è½½æˆåŠŸï¼")

                            # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢ä¸ºevalæ¨¡å¼
                            if hasattr(model, 'eval'):
                                model = model.eval()
                        except Exception as e2:
                            # å°è¯•ä½œä¸ºTorchScriptåŠ è½½
                            st.info("å¸¸è§„åŠ è½½å¤±è´¥ï¼Œå°è¯•ä½œä¸ºTorchScriptåŠ è½½...")
                            model = torch.jit.load(tmp_path, map_location=torch.device('cpu'))
                            st.success("TorchScriptæ¨¡å‹åŠ è½½æˆåŠŸï¼")
            else:
                # æ²¡æœ‰å®‰è£…ultralyticsåº“ï¼Œç›´æ¥å°è¯•å¸¸è§„åŠ è½½
                try:
                    # å°è¯•å¸¸è§„åŠ è½½
                    model = torch.load(tmp_path, map_location=torch.device('cpu'))
                    st.success("PyTorchæ¨¡å‹åŠ è½½æˆåŠŸï¼")

                    # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢ä¸ºevalæ¨¡å¼
                    if hasattr(model, 'eval'):
                        model = model.eval()
                except Exception as e:
                    # å°è¯•ä½œä¸ºTorchScriptåŠ è½½
                    st.info("å¸¸è§„åŠ è½½å¤±è´¥ï¼Œå°è¯•ä½œä¸ºTorchScriptåŠ è½½...")
                    model = torch.jit.load(tmp_path, map_location=torch.device('cpu'))
                    st.success("TorchScriptæ¨¡å‹åŠ è½½æˆåŠŸï¼")

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(tmp_path)

        # æ¨¡å‹æµ‹è¯•æ¨ç†ï¼ˆä»…åœ¨ä¸Šä¼ æ¨¡å‹åæ‰§è¡Œï¼‰
        if test_model_inference(model, model_type):
            st.info("æ¨¡å‹æµ‹è¯•æ¨ç†æˆåŠŸï¼Œå‡†å¤‡å°±ç»ªï¼")
        else:
            st.warning("æ¨¡å‹æµ‹è¯•æ¨ç†è¿”å›æ„å¤–ç»“æœï¼Œä½†ç»§ç»­è¿è¡Œã€‚")

        return model

    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        logger.error(f"æ¨¡å‹åŠ è½½é”™è¯¯: {e}", exc_info=True)
        return None


# æµ‹è¯•æ¨¡å‹æ¨ç†
def test_model_inference(model, model_type):
    try:
        # åˆ›å»ºä¸€ä¸ªéšæœºæµ‹è¯•å›¾åƒ
        test_img = torch.rand(1, 3, 640, 640)

        # æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´è¾“å…¥
        if model_type == "ONNX":
            # ONNXæ¨¡å‹æ¨ç†
            input_name = model.get_inputs()[0].name
            with torch.no_grad():
                output = model.run(None, {input_name: test_img.numpy()})
        else:
            # PyTorch/TorchScriptæ¨¡å‹æ¨ç†
            with torch.no_grad():
                if hasattr(model, 'forward'):
                    output = model.forward(test_img)
                else:
                    output = model(test_img)

        # ç®€å•éªŒè¯è¾“å‡º
        if model_type == "ONNX":
            # æ£€æŸ¥ONNXè¾“å‡ºæ ¼å¼
            if isinstance(output, list) and len(output) > 0:
                return True
        else:
            # æ£€æŸ¥PyTorchè¾“å‡ºæ ¼å¼
            if isinstance(output, dict) and 'boxes' in output:
                return True
            elif isinstance(output, list) and len(output) > 0:
                return True

        logger.warning(f"æ¨¡å‹æµ‹è¯•è¾“å‡ºæ ¼å¼ä¸åŒ¹é…ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
        return True  # å®½å®¹å¤„ç†ï¼Œå…è®¸ä¸åŒæ ¼å¼

    except Exception as e:
        logger.warning(f"æ¨¡å‹æµ‹è¯•æ¨ç†å¤±è´¥: {e}")
        return True  # å®½å®¹å¤„ç†ï¼Œé¿å…é˜»æ­¢åº”ç”¨è¿è¡Œ


# å¤„ç†å›¾åƒ
def process_image(image, model, model_type, threshold, color_hex):
    if model is None:
        # ä½¿ç”¨ç¤ºä¾‹æ£€æµ‹ç»“æœ
        st.warning("ä½¿ç”¨ç¤ºä¾‹æ£€æµ‹ç»“æœï¼Œå› ä¸ºæ²¡æœ‰åŠ è½½æœ‰æ•ˆæ¨¡å‹")
        return generate_example_result(image, threshold, color_hex)

    try:
        # è½¬æ¢ä¸ºRGB
        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        img_tensor, original_info = preprocess_image(img_rgb)

        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            if model_type == "ONNX":
                input_name = model.get_inputs()[0].name
                outputs = model.run(None, {input_name: img_tensor.numpy()})
                results = postprocess_onnx_output(outputs, original_info)
            else:
                outputs = model(img_tensor)
                results = postprocess_pytorch_output(outputs, original_info, model_type)

        # è§£æç»“æœ
        boxes = results['boxes']
        scores = results['scores']

        # è¿‡æ»¤ä½ç½®ä¿¡åº¦é¢„æµ‹
        filtered_indices = np.where(scores >= threshold)[0]
        filtered_boxes = boxes[filtered_indices]
        filtered_scores = scores[filtered_indices]

        # ç»˜åˆ¶ç»“æœ
        img_with_boxes = img_rgb.copy()
        total_bad = len(filtered_boxes)

        # è½¬æ¢é¢œè‰²å¹¶å¤„ç†OpenCVçš„BGRæ ¼å¼
        color = hex_to_rgb(color_hex)
        color_bgr = (color[2], color[1], color[0])  # è½¬æ¢ä¸ºBGRæ ¼å¼

        for box, score in zip(filtered_boxes, filtered_scores):
            x1, y1, x2, y2 = map(int, box)

            # ç¡®ä¿è¾¹ç•Œæ¡†åœ¨å›¾åƒèŒƒå›´å†…
            x1 = max(0, x1)
            y1 = max(0, y1)
            x2 = min(img_with_boxes.shape[1], x2)
            y2 = min(img_with_boxes.shape[0], y2)

            # è·³è¿‡æ— æ•ˆçš„è¾¹ç•Œæ¡†
            if x1 >= x2 or y1 >= y2:
                continue

            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            if draw_bbox:
                cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color_bgr, line_thickness)

            # ç»˜åˆ¶æ ‡ç­¾å’Œç½®ä¿¡åº¦
            if draw_label or draw_confidence:
                text = "åç²’"
                if draw_confidence:
                    text += f": {score:.2f}"

                # ç¡®ä¿æ–‡æœ¬ä½ç½®åœ¨å›¾åƒèŒƒå›´å†…
                text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                text_x = x1
                text_y = max(y1 - 10, text_size[1] + 10)  # ç¡®ä¿æ–‡æœ¬ä¸ä¼šè¶…å‡ºå›¾åƒé¡¶éƒ¨

                cv2.putText(
                    img_with_boxes,
                    text,
                    (text_x, text_y),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    color_bgr,
                    2
                )

        return img_with_boxes, total_bad

    except Exception as e:
        st.error(f"å›¾åƒå¤„ç†å¤±è´¥: {e}")
        logger.error(f"å›¾åƒå¤„ç†é”™è¯¯: {e}", exc_info=True)
        # ç”Ÿæˆç¤ºä¾‹ç»“æœ
        return generate_example_result(image, threshold, color_hex)


# æ ‡ç­¾æ˜ å°„ï¼ˆæ ¹æ®æ¨¡å‹è¾“å‡ºï¼Œå¼ºåˆ¶æ˜ å°„ä¸ºâ€œåç²’â€ï¼‰
def get_label(class_id):
    return "åç²’"  # æ¨¡å‹åªæœ‰ä¸€ç§æ ‡ç­¾ï¼Œç›´æ¥è¿”å›ä¸­æ–‡


# å›¾åƒé¢„å¤„ç† - æ”¹è¿›ç‰ˆæœ¬ï¼Œé¿å…åŒé‡å½’ä¸€åŒ–
def preprocess_image(image):
    original_h, original_w = image.shape[:2]
    target_size = 640
    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆä¿æŒåŸå›¾æ¯”ä¾‹ï¼‰
    scale = min(target_size / original_w, target_size / original_h)
    new_w, new_h = int(original_w * scale), int(original_h * scale)
    # ç¼©æ”¾å›¾åƒ
    resized_img = cv2.resize(image, (new_w, new_h))
    # åˆ›å»ºå¸¦ padding çš„å›¾åƒï¼ˆç°è¾¹å¡«å……ï¼Œä¹Ÿå¯é»‘è‰²ï¼Œä¸å½±å“æ£€æµ‹ï¼‰
    padded_img = np.full((target_size, target_size, 3), 128, dtype=np.uint8)  # 128 æ˜¯ç°è‰²ï¼Œæ–¹ä¾¿è°ƒè¯•çœ‹ padding
    # è®¡ç®— padding ä½ç½®ï¼Œè®©å›¾åƒå±…ä¸­
    pad_top = (target_size - new_h) // 2
    pad_left = (target_size - new_w) // 2
    padded_img[pad_top:pad_top + new_h, pad_left:pad_left + new_w] = resized_img

    # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥å¼ é‡ï¼ˆå½’ä¸€åŒ–ï¼‰
    img_tensor = torch.from_numpy(padded_img).permute(2, 0, 1).float().unsqueeze(0) / 255.0
    # è®°å½•é¢„å¤„ç†ä¿¡æ¯ï¼Œç”¨äºåå¤„ç†è¿˜åŸ
    return img_tensor, {
        "original_size": (original_h, original_w),
        "resized_size": (new_h, new_w),
        "pad_top": pad_top,
        "pad_left": pad_left,
        "scale": scale
    }


# åå¤„ç†PyTorchæ¨¡å‹è¾“å‡º - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼
def postprocess_pytorch_output(outputs, preprocess_info, model_type):
    try:
        original_h, original_w = preprocess_info["original_size"]
        scale = preprocess_info["scale"]
        pad_top = preprocess_info["pad_top"]
        pad_left = preprocess_info["pad_left"]

        # é€‚é…ä¸åŒæ¨¡å‹è¾“å‡ºï¼ˆä»¥ YOLO ç³»åˆ—ä¸ºä¾‹ï¼Œè¾“å‡ºæ ¼å¼æ˜¯ [batch, boxes, [x1,y1,x2,y2,score,...]]ï¼‰
        if ULTRALYTICS_AVAILABLE and isinstance(outputs, list) and len(outputs) > 0:
            if hasattr(outputs[0], "boxes"):
                # YOLOv8 æ ¼å¼
                pred_boxes = outputs[0].boxes
                boxes = pred_boxes.xyxy.cpu().numpy()  # åŸå§‹åæ ‡æ˜¯åŸºäº 640Ã—640 çš„
                scores = pred_boxes.conf.cpu().numpy()
            else:
                # å…¶ä»–æ ¼å¼ï¼ˆå¦‚ YOLOv5 ç›´æ¥è¾“å‡ºå¼ é‡ï¼‰
                pred = outputs[0].cpu().numpy()
                boxes = pred[..., :4]  # x1,y1,x2,y2
                scores = pred[..., 4]  # score
        else:
            # å…œåº•ï¼šå‡è®¾è¾“å‡ºæ˜¯å¼ é‡æˆ–å­—å…¸ï¼ˆæ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´ï¼‰
            raise ValueError("æ¨¡å‹è¾“å‡ºæ ¼å¼æœªé€‚é…ï¼Œè¯·æ ¹æ®æ¨¡å‹ç±»å‹è°ƒæ•´åå¤„ç†é€»è¾‘ï¼")

        # è¿˜åŸè¾¹ç•Œæ¡†åˆ°åŸå›¾å°ºå¯¸ï¼šå…ˆå‡å» paddingï¼Œå†æŒ‰ç¼©æ”¾æ¯”ä¾‹è¿˜åŸ
        boxes[:, 0] = (boxes[:, 0] - pad_left) / scale
        boxes[:, 1] = (boxes[:, 1] - pad_top) / scale
        boxes[:, 2] = (boxes[:, 2] - pad_left) / scale
        boxes[:, 3] = (boxes[:, 3] - pad_top) / scale

        # è¾¹ç•Œæ¡†åæ ‡é™åˆ¶åœ¨åŸå›¾èŒƒå›´å†…
        boxes[:, 0] = np.clip(boxes[:, 0], 0, original_w)
        boxes[:, 1] = np.clip(boxes[:, 1], 0, original_h)
        boxes[:, 2] = np.clip(boxes[:, 2], 0, original_w)
        boxes[:, 3] = np.clip(boxes[:, 3], 0, original_h)

        return {"boxes": boxes, "scores": scores}
    except Exception as e:
        logger.error(f"PyTorch è¾“å‡ºåå¤„ç†å¤±è´¥: {e}", exc_info=True)
        # ç¤ºä¾‹ç»“æœå…œåº•
        return {
            "boxes": np.array([[100, 100, 200, 200], [300, 300, 400, 400]]),
            "scores": np.array([0.8, 0.7])
        }


# åå¤„ç†ONNXæ¨¡å‹è¾“å‡º - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼
def postprocess_onnx_output(outputs, original_info):
    try:
        # è°ƒè¯•è¾“å‡ºï¼šæ‰“å°è¾“å‡ºç±»å‹å’Œç»“æ„
        logger.debug(f"ONNXæ¨¡å‹è¾“å‡ºæ•°é‡: {len(outputs)}")
        for i, output in enumerate(outputs):
            logger.debug(f"è¾“å‡º {i} å½¢çŠ¶: {output.shape}")

        # å¤„ç†å¸¸è§çš„ONNXè¾“å‡ºæ ¼å¼
        boxes = None
        scores = None

        # å°è¯•æ ‡å‡†æ ¼å¼ [boxes, scores]
        if len(outputs) >= 2:
            boxes = outputs[0]
            scores = outputs[1]

            if boxes.ndim == 3:
                boxes = boxes[0]  # ç§»é™¤batchç»´åº¦
            if scores.ndim == 2:
                scores = scores[0]  # ç§»é™¤batchç»´åº¦

            logger.info("æ£€æµ‹åˆ°æ ‡å‡†ONNXæ ¼å¼è¾“å‡º")

        # å°è¯•YOLOæ ¼å¼ [n, 85] æˆ– [1, n, 85]
        elif len(outputs) == 1 and outputs[0].ndim in [2, 3]:
            pred = outputs[0]
            if pred.ndim == 3:
                pred = pred[0]  # ç§»é™¤batchç»´åº¦

            boxes = pred[:, :4]  # x1, y1, x2, y2
            scores = pred[:, 4]  # confidence
            logger.info("æ£€æµ‹åˆ°YOLO ONNXæ ¼å¼è¾“å‡º")

        else:
            raise ValueError("æ— æ³•è¯†åˆ«çš„ONNXæ¨¡å‹è¾“å‡ºæ ¼å¼")

        # è°ƒæ•´è¾¹ç•Œæ¡†å¤§å°ä»¥åŒ¹é…åŸå§‹å›¾åƒ
        original_size = original_info['original_size']
        new_size = original_info['new_size']
        pad = original_info['pad']

        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        scale_x = original_size[1] / new_size[0]
        scale_y = original_size[0] / new_size[1]

        # è°ƒæ•´è¾¹ç•Œæ¡†åæ ‡
        boxes[:, 0] = (boxes[:, 0] - pad[0] / 2) * scale_x
        boxes[:, 1] = (boxes[:, 1] - pad[1] / 2) * scale_y
        boxes[:, 2] = (boxes[:, 2] - pad[0] / 2) * scale_x
        boxes[:, 3] = (boxes[:, 3] - pad[1] / 2) * scale_y

        return {'boxes': boxes, 'scores': scores}

    except Exception as e:
        logger.error(f"ONNXè¾“å‡ºåå¤„ç†å¤±è´¥: {e}", exc_info=True)
        # è¿”å›ç¤ºä¾‹ç»“æœ
        return {
            'boxes': np.array([[100, 100, 200, 200], [300, 300, 400, 400]]),
            'scores': np.array([0.8, 0.7])
        }


# ç”Ÿæˆç¤ºä¾‹ç»“æœ
def generate_example_result(image, threshold, color_hex):
    img_with_boxes = image.copy()
    height, width = image.shape[:2]

    # è½¬æ¢é¢œè‰²å¹¶å¤„ç†OpenCVçš„BGRæ ¼å¼
    color = hex_to_rgb(color_hex)
    color_bgr = (color[2], color[1], color[0])  # è½¬æ¢ä¸ºBGRæ ¼å¼

    # éšæœºç”Ÿæˆä¸€äº›ç¤ºä¾‹æ£€æµ‹æ¡†
    num_detections = np.random.randint(1, 10)
    total_bad = 0

    for _ in range(num_detections):
        score = np.random.uniform(threshold, 1.0)
        if score >= threshold:
            total_bad += 1

            # éšæœºä½ç½®å’Œå¤§å°ï¼Œä½†ç¡®ä¿åœ¨å›¾åƒèŒƒå›´å†…
            x1 = np.random.randint(0, width // 2)
            y1 = np.random.randint(0, height // 2)
            x2 = np.random.randint(x1 + 10, width)
            y2 = np.random.randint(y1 + 10, height)

            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            if draw_bbox:
                cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color_bgr, line_thickness)

            # ç»˜åˆ¶æ ‡ç­¾å’Œç½®ä¿¡åº¦
            if draw_label or draw_confidence:
                text = "åç²’"
                if draw_confidence:
                    text += f": {score:.2f}"

                # ç¡®ä¿æ–‡æœ¬ä½ç½®åœ¨å›¾åƒèŒƒå›´å†…
                text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                text_x = x1
                text_y = max(y1 - 10, text_size[1] + 10)  # ç¡®ä¿æ–‡æœ¬ä¸ä¼šè¶…å‡ºå›¾åƒé¡¶éƒ¨

                cv2.putText(
                    img_with_boxes,
                    text,
                    (text_x, text_y),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    color_bgr,
                    2
                )

    return img_with_boxes, total_bad


# åå…­è¿›åˆ¶é¢œè‰²è½¬RGB
def hex_to_rgb(hex_color):
    hex_color = hex_color.lstrip('#')
    return tuple(int(hex_color[i:i + 2], 16) for i in (0, 2, 4))


# ä¸»ç•Œé¢
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ä¸Šä¼ å›¾åƒ")

    # ä¸Šä¼ å›¾åƒæ–‡ä»¶
    uploaded_file = st.file_uploader(
        "é€‰æ‹©ä¸€å¼ å›¾ç‰‡",
        type=["jpg", "jpeg", "png", "bmp"]
    )

    # æˆ–è€…ä»æ‘„åƒå¤´æ•è·
    use_camera = st.checkbox("ä½¿ç”¨æ‘„åƒå¤´æ‹æ‘„")
    if use_camera:
        uploaded_file = st.camera_input("æ‹æ‘„ç‰ç±³ç…§ç‰‡")

    if uploaded_file is not None:
        # æ˜¾ç¤ºåŸå§‹å›¾åƒ
        st.subheader("åŸå§‹å›¾åƒ")


# åŠ è½½æ¨¡å‹
model = load_model(model_file, model_type)
